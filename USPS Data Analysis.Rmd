---
title: "USPS Data Analysis"
author: "Eddie Sun"
date: "6/19/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(purrr)
library(foreign)
library(tidyverse)
library(sf)
```


# Read in data
```{r}
setwd("C:\\Users\\edwinysun\\Box\\Terner Center_Summer 2019\\USPS Data\\Raw data")

temp <- list.files(path = "C:\\Users\\edwinysun\\Box\\Terner Center_Summer 2019\\USPS Data\\Raw data", pattern = "*.dbf")
filepath <- "C:\\Users\\edwinysun\\Box\\Terner Center_Summer 2019\\USPS Data\\Raw data\\"
temp <- paste0(filepath, temp)
tbl <- lapply(temp, foreign::read.dbf)

setwd("C:\\Users\\edwinysun\\Box\\Terner Center_Summer 2019\\USPS Data\\USPS Data Analysis")
```

# Merging all years into one long dataframe
```{r}
tbl <- tbl[4:14]
# Drops data years 2005-2007

for (i in seq_along(tbl)) {
  colnames(tbl[[i]]) <- toupper(colnames(tbl[[i]]))
}
# Converts column names to all upper case, as we need to select text and R is case-sensitive. 

names(tbl) <- c(2008:2018)
# Names the list's elements

df <- bind_rows(tbl, .id = "YEAR")
```

# 


# There seems to be some kind of machine error in this code chunk that ran fine for the past several weeks and now doesn't work.
```{r}

# Write a function for joining each year's data into one df using GEOID as key.
# We can't use the joins that drop some values: full_join seems to be the best one.
# Take the first element in the list, join the second (i, i + 1)
# Change column names by appending the year: add argument suffix = 
# Need to extract each of the 13 elements from the list
 

list_to_df <- function(list, year) {
  year <- 2005
  year <- year-1
  list <- tbl
  
  df <- as_data_frame(list[[1]])
  for (i in seq(from = 2, to = length(list), by = 1)) {
    df <- df %>% full_join(as_data_frame(list[[i]]),  
                           by = "GEOID",
                           suffix = c(
                                      "",
                                      paste0("-", as.character(year + i))
                                      )
                           )
  df
  }
  df
}
#This function didn't work at first, because some years have GEOID in all caps and other years have it in lower case.

# for (i in seq(from = 11, to = length(tbl))) {
#   tbl[[i]] <- tbl[[i]] %>% rename(GEOID = geoid)
# }
# Used this for loop to rename the geoid column to all caps.

for (i in seq_along(tbl)) {
  tbl[[i]] <- tbl[[i]] %>% mutate(GEOID = as.character("GEOID"))
}
# Used this for loop to coerce all the factor classes to strings. 

for (i in seq_along(tbl)) {
  colnames(tbl[[i]]) <- toupper(colnames(tbl[[i]]))
}
# Converts column names to all upper case, as we need to select text and R is case-sensitive. 

df <- list_to_df()
# Note that because the 2005-2007 data have a different structure than the rest of the years, the suffix system restarts in 2008 (i.e. 2005 has no suffix, but data for years 2006 and 2007 have suffixes; 2008 has no suffix, but subsequent years have suffixes).

df <- as_data_frame(tbl[[1]])
df <- df %>% full_join(tbl[[2]], by = "GEOID", suffix = c("2005", paste0("-", as.character(2006))))

df <- df %>% select(-c(2:44))
# Removing years 2005-2007 because it's too different from the other years and too limited in that it doesn't parse out residential counts.

names(df)[2:61] <- paste0(names(df)[2:61], sep = "-", "2008")
# Add "2008" suffix to the first year
```

## Initial subsetting of the data
```{r}
# Filter for California 06- and Los Angeles County -037-

df <- df %>% separate(col = GEOID, into = c("State", "County", NA), sep = c(2, 5), remove = FALSE)
# Pulled out the state and county codes from GEOID.

la_county <- df %>% filter(State == "06" & County == "037")
# Filtered for census tracts in California and LA County.

alameda_county <- df %>% filter(State == "06" & County == "001")
# Filtered for census tracts in California and Alameda County.
```

# Summary statistics and visualizations of Los Angeles residential vacancy
```{r}

grep(la_county, pattern = "AMS_RES", x = colnames(la_county))
# The above gives you a vector of columns in which the pattern appears. 
la_county[grep(la_county, pattern = "AMS_RES", x = colnames(la_county))]
# This subsets the dataset down to only columns in which the pattern appears. 
la_res_count <- la_county[grep(la_county, pattern = "AMS_RES", x = colnames(la_county))] %>% lapply(mean, na.rm = TRUE) %>% unlist()
# lapply() takes a list, or coerces objects into a list, and applies the same function to all of them. The subset above is already a dataframe that can be coerced into a list.
# This is the average count of residential addresses per census tract.

la_res_vac_count <- la_county[grep(la_county, pattern = "RES_VAC", x = colnames(la_county))] %>% colMeans(na.rm = TRUE) 
# Average count of vacant residential addresses per census tract.

la_res_nostat_count <- la_county[grep(la_county, pattern = "NOSTAT_RES", x = colnames(la_county))] %>% colMeans(na.rm = TRUE) 
# Average count of no-stat residential addresses per census tract.

la_res_active_count <- (la_res_count - la_res_vac_count - la_res_nostat_count)
la_res_active_count <- la_res_active_count %>% enframe()

la_res_count <- la_res_count %>% enframe()

la_res_vac_count <- la_res_vac_count %>% enframe()

la_res_nostat_count <- la_res_nostat_count %>% enframe()

# To create a ggplot that stacks the bars each year, we need the x= to be each year and fill= to be the activity status of the address. Need to make this data wide. 
la_res_active_count <- la_res_active_count %>% spread(key = name, value = value) 
#Assigning new names to the columns so that all columns are years only
la_res_active_count <- la_res_active_count %>% rename_all(funs(replace(., list = c(1:11), values = c(2008:2018))))
#Add tracker variable to show that this is a mean for active counts
la_res_active_count <- la_res_active_count %>% mutate(occupancy_type = "res_active") %>% select(occupancy_type, everything())

#Do this for all the other counts
la_res_count <- la_res_count %>% spread(key = name, value = value) 
la_res_count <- la_res_count %>% rename_all(funs(replace(., list = c(1:11), values = c(2008:2018)))) 
la_res_count <- la_res_count %>% mutate(occupancy_type = "res_total") %>% select(occupancy_type, everything())

la_res_vac_count <- la_res_vac_count %>% spread(key = name, value = value) %>% rename_all(funs(replace(., list = c(1:11), values = c(2008:2018)))) %>% mutate(occupancy_type = "res_vacant") %>% select(occupancy_type, everything())

la_res_nostat_count <- la_res_nostat_count %>% spread(key = name, value = value) %>% rename_all(funs(replace(., list = c(1:11), values = c(2008:2018)))) %>% mutate(occupancy_type = "res_nostat") %>% select(occupancy_type, everything())

# Note to self: the row label tracking the originating dataframe could have been accomplished with the bind_rows function's .id argument. 
# Appending all the counts together except the total, since the bar chart will sum up the counts.
la_county_means <- bind_rows(la_res_nostat_count, la_res_vac_count, la_res_active_count)

la_county_means <- la_county_means %>% gather(key = "year", value = "mean_count", "2008":"2018")

la_county_means %>% ggplot(aes(x = year, y = mean_count)) + geom_col(aes(fill = occupancy_type), position = "dodge") + ggtitle(label ="Changes in Residential Occupancy, Vacancy, and Development", subtitle = "The Mean Census Tract in Los Angeles County")

ggsave("la_county.png", width = 9, height = 7)
```

# Summary statistics and visualizations of Alameda residential vacancy
```{r}

alameda_res_count <- alameda_county[grep(alameda_county, pattern = "AMS_RES", x = colnames(alameda_county))] %>% colMeans(na.rm = TRUE) 
# Average of residential addresses per census tract.

alameda_res_vac_count <- alameda_county[grep(alameda_county, pattern = "RES_VAC", x = colnames(alameda_county))] %>% colMeans(na.rm = TRUE) 
# Average count of vacant residential addresses per census tract. 

alameda_res_nostat_count <- alameda_county[grep(alameda_county, pattern = "NOSTAT_RES", x = colnames(alameda_county))] %>% colMeans(na.rm = TRUE) 
# Average count of nostat residential addresses per census tract.

alameda_res_active_count <- (alameda_res_count - alameda_res_vac_count - alameda_res_nostat_count) %>% enframe()
# Average count of active residential addresses per census tract.

alameda_res_count <- enframe(alameda_res_count)
alameda_res_vac_count <- enframe(alameda_res_vac_count)
alameda_res_nostat_count <- enframe(alameda_res_nostat_count)
# Coercing vectors of averages into dataframes.

alameda_res_active_count <- alameda_res_active_count %>% separate(col = name, into = c("occupancy_type", "year"), sep = "-")
# alameda_res_active_count[1,2] <- "2008"
alameda_res_active_count$occupancy_type <- "res_active"
# Separate the name columns into a string denoting the occupancy type and a string denoting the year

alameda_res_vac_count <- alameda_res_vac_count %>% separate(col = name, into = c("occupancy_type", "year"), sep = "-")
# alameda_res_vac_count$year[1] <- "2008"
alameda_res_vac_count$occupancy_type <- "res_vacant"
# Separate the name columns into a string denoting the occupancy type and a string denoting the year

alameda_res_nostat_count <- alameda_res_nostat_count %>% separate(col = name, into = c("occupancy_type", "year"), sep = "-")
# alameda_res_nostat_count$year[1] <- "2008"
alameda_res_nostat_count$occupancy_type <- "res_nostat"
# Separate the name columns into a string denoting the occupancy type and a string denoting the year

alameda_county_means <- bind_rows(alameda_res_active_count, alameda_res_vac_count, alameda_res_nostat_count)
alameda_county_means <- rename(alameda_county_means, mean_count = value)
# Appending all the counts together except the total, since the bar chart will sum up the counts.

alameda_county_means %>% ggplot(aes(x = year, y = mean_count)) + geom_col(aes(fill = occupancy_type), position = "dodge") + ggtitle(label ="Changes in Residential Occupancy, Vacancy, and Development", subtitle = "The Mean Census Tract in Alameda County")

ggsave("alameda_county.png", width = 9, height = 7)
```

# GIS visualizations of the res_nostat variable for LA
```{r}
la_shp <- st_read("\\Users\\edwinysun\\Box\\Terner Center_Summer 2019\\USPS Data\\Raw data\\Shapefiles\\CENSUS_TRACTS_2010.shp")
la_shp <- rename(la_shp, GEOID = GEOID10)
la_shp <- right_join(df, la_shp, by = "GEOID")

ggplot() + geom_sf(data = la_shp, aes(fill = "NOSTAT_RES-2008", palette = "Blues")) + ylim(1700000, 2130000) + ggtitle("LA 2008")
ggsave("LA 2008.png", width = 8, height = 8)

ggplot() + geom_sf(data = la_shp, aes(fill = "NOSTAT_RES-2018", palette = "Blues")) + ylim(1700000, 2130000) + ggtitle("LA 2018")
ggsave("LA 2018.png", width = 8, height = 8)

# We should gather the data into a long table and facet wrap by year, and also re-express the nostat counts as proportions of total residential.

la_shp <- la_shp %>% mutate(PROP_NOSTAT_RES = NOSTAT_RES/AMS_RES) %>% select(GEOID, State, County, YEAR, PROP_NOSTAT_RES, everything())

ggplot() + geom_sf(data = la_shp, aes(fill = "PROP_NOSTAT_RES")) + scale_fill_viridis_d(option = "plasma") + ylim(1700000, 2130000) + facet_wrap(~YEAR) + ggtitle("LA 2008-2018")
ggsave("LA 2008-2018.png", width = 24, height = 24)

for (i in unique(la_shp$YEAR)){
la_shp %>% 
    filter(YEAR == i) %>% 
      ggplot() + geom_sf(aes(fill = PROP_NOSTAT_RES)) + scale_fill_viridis_c(option = "plasma") + ylim(1700000, 2130000) + ggtitle(paste0("LA County Proportion NOSTAT_RES in Year ", i))
  
  ggsave(paste0("LA_prop_nostat_res_", i, ".png"), width = 10, height = 9)
}

for (i in unique(la_shp$YEAR)){
la_shp %>% 
    filter(YEAR == i) %>% 
      ggplot() + geom_sf(aes(fill = NOSTAT_RES)) + scale_fill_viridis_c(option = "plasma", breaks = c(750, 1500, 2250, 3000, 3750, 4500, 5250, 6000), limits = c(0, 6000)) + ylim(1700000, 2130000) + ggtitle(paste0("LA County Count of NOSTAT_RES in Year ", i))
  
  ggsave(paste0("LA_count_nostat_res_", i, ".png"), width = 10, height = 9)
}
```

# GIS visualizations of the nostat_res variable for Alameda
```{r}
alameda_shp <- st_read("\\Users\\edwinysun\\Box\\Terner Center_Summer 2019\\USPS Data\\Raw data\\Shapefiles\\geo_export_e7743e61-6b88-4db0-9252-b97da0a07018.shp")
alameda_shp <- rename(alameda_shp, GEOID = geoid10, x_center = intptlat10, y_center = intptlon10)
alameda_shp <- right_join(df, alameda_shp, by = "GEOID")

alameda_shp <- alameda_shp %>% mutate(PROP_NOSTAT_RES = NOSTAT_RES/AMS_RES) %>% select(GEOID, State, County, YEAR, PROP_NOSTAT_RES, everything())
alameda_shp <- st_as_sf(alameda_shp)
alameda_shp <- st_transform(alameda_shp, crs = "+init=epsg:2227")

for (i in unique(alameda_shp$YEAR)){
alameda_shp %>% 
    filter(YEAR == i) %>% 
      ggplot() + geom_sf(aes(fill = PROP_NOSTAT_RES)) + scale_fill_viridis_c(option = "plasma", limits = c(0, 1), breaks = c(0, .25, .5, .75, 1)) + ggtitle(paste0("Alameda County Proportion NOSTAT_RES in Year ", i))
  
  ggsave(paste0("Alameda_prop_nostat_res_", i, ".png"), width = 10, height = 9)
}

for (i in unique(alameda_shp$YEAR)){
alameda_shp %>% 
    filter(YEAR == i) %>% 
      ggplot() + geom_sf(aes(fill = NOSTAT_RES)) + scale_fill_viridis_c(option = "plasma", breaks = c(750, 1500, 2250, 3000, 3750, 4500, 5250, 6000), limits = c(0, 6000)) + ylim(1700000, 2130000) + ggtitle(paste0("Alameda County Count of NOSTAT_RES in Year ", i))
  
  ggsave(paste0("Alameda_count_nostat_res_", i, ".png"), width = 10, height = 9)
}
```

# GIS visualizations of the nostat_res variable for SF
```{r}
sf_shp <- st_read("\\Users\\edwinysun\\Box\\Terner Center_Summer 2019\\USPS Data\\Raw data\\Shapefiles\\geo_export_d67a3e99-216a-4ca5-ac2c-5549ecee5acb.shp")
sf_shp <- rename(sf_shp, GEOID = geoid10, x_center = intptlat10, y_center = intptlon10)
sf_shp <- right_join(df, sf_shp, by = "GEOID")

sf_shp <- sf_shp %>% mutate(PROP_NOSTAT_RES = NOSTAT_RES/AMS_RES) %>% select(GEOID, State, County, YEAR, PROP_NOSTAT_RES, everything())

sf_shp <- st_as_sf(sf_shp)
sf_shp <- st_transform(sf_shp, crs = "+init=epsg:2227")

for (i in unique(sf_shp$YEAR)){
sf_shp %>% 
    filter(YEAR == i) %>% 
      ggplot() + geom_sf(aes(fill = PROP_NOSTAT_RES)) + scale_fill_viridis_c(option = "plasma", limits = c(0, 1), breaks = c(0, .25, .5, .75, 1)) + ggtitle(paste0("San Francisco Proportion NOSTAT_RES in Year ", i))
  
  ggsave(paste0("SF_prop_nostat_res_", i, ".png"), width = 11, height = 9)
}
```

# Reading in and joining the ACS data for LA
```{r}
acs <- read.csv("C:\\Users\\edwinysun\\Box\\Terner Center_Summer 2019\\USPS Data\\Raw data\\ACS\\Aggregated_Nghbr_Census&ACS_1990to2016.csv")

# The acs data is wide, and the LA/SF/Alameda data are long. To merge, we have to spread the county data and join by GEOID
# It is difficult to group_by year to compute quintiles in wide. Gather the LA/SF/Alameda data into even longer format in order to add indicator variables for each census tract's quantile grouping for each occupancy variable.

la_quintiles <- la_shp %>% select(-c(66:73))
# Dropped the geometry because it was messing up the gather.

la_quintiles <- gather(la_shp, "count_type", "counts", c(5:65))
la_quintiles <- la_quintiles %>% arrange(GEOID)
# Reshaped the data to make the occupany variables long.

la_quintiles <- la_quintiles %>% select(GEOID, State, County, count_type, YEAR, counts) %>% unite(col = "key", c(count_type, YEAR), sep = "-")
# Combined the year and occupany type variables into one column.

la_quintiles$counts <- as.numeric(la_quintiles$counts)

la_quintiles <- la_quintiles %>% group_by(key) %>% mutate(quintile1 = quantile(counts, probs = 0.2, na.rm = TRUE), quintile2 = quantile(counts, probs = 0.4, na.rm = TRUE), quintile3 = quantile(counts, probs = 0.6, na.rm = TRUE), quintile4 = quantile(counts, probs = 0.8, na.rm = TRUE))

# Found quantiles for each occupancy type/year grouping

la_quintiles <- la_quintiles %>% mutate(quintile = case_when(counts <= quintile1 ~ 1,
                                                                   (counts > quintile1 & counts <= quintile2) ~ 2,
                                                                   (counts > quintile2 & counts <= quintile3) ~ 3,
                                                                   (counts > quintile3 & counts <= quintile4) ~ 4,
                                                                   counts > quintile4 ~ 5,
                                                                   TRUE ~ 0)
                                              )
# Created quintile ranks for each occupancy type/year grouping.

la_quintiles <- la_quintiles %>% select(GEOID, key, quintile)

la_quintiles <- spread(la_quintiles, key = key, value = quintile)
# Reshaping the rankings to wide

acs <- acs %>% select("Geo_GEOID", "ACS16_5yr_B25003002", "ACS16_5yr_B25003003", "ACS16_5yr_B25024001", "ACS16_5yr_B25024002", "ACS16_5yr_B03002003", "ACS16_5yr_B03002004", "ACS16_5yr_B03002005", "ACS16_5yr_B03002006", "ACS16_5yr_B03002007", "ACS16_5yr_B03002008", "ACS16_5yr_B03002009", "ACS16_5yr_B03002012", "ACS16_5yr_B19001002", "ACS16_5yr_B19001003", "ACS16_5yr_B19001004", "ACS16_5yr_B19001005", "ACS16_5yr_B19001006", "ACS16_5yr_B19001007", "ACS16_5yr_B19001008", "ACS16_5yr_B19001009", "ACS16_5yr_B19001010", "ACS16_5yr_B19001011", "ACS16_5yr_B19001012", "ACS16_5yr_B19001013", "ACS16_5yr_B19001014", "ACS16_5yr_B19001015", "ACS16_5yr_B19001016", "ACS16_5yr_B19001017", "ACS16_5yr_B15003002", "ACS16_5yr_B15003003", "ACS16_5yr_B15003004", "ACS16_5yr_B15003005", "ACS16_5yr_B15003006", "ACS16_5yr_B15003007", "ACS16_5yr_B15003008", "ACS16_5yr_B15003009", "ACS16_5yr_B15003010", "ACS16_5yr_B15003011", "ACS16_5yr_B15003012", "ACS16_5yr_B15003013", "ACS16_5yr_B15003014", "ACS16_5yr_B15003015", "ACS16_5yr_B15003016", "ACS16_5yr_B15003017", "ACS16_5yr_B15003018", "ACS16_5yr_B15003019", "ACS16_5yr_B15003020", "ACS16_5yr_B15003021", "ACS16_5yr_B15003022", "ACS16_5yr_B15003023", "ACS16_5yr_B15003024", "ACS16_5yr_B15003025", "ACS16_5yr_B19057001", "ACS16_5yr_B19057002", "ACS16_5yr_B19057003")
# Dropping irrelevant ACS variables.

acs <- acs %>% separate(col = Geo_GEOID, into = c(NA, "GEOID"), sep = "US")
# Parsing the Geo_GEOID variable.

la_demographics <- left_join(x = la_quintiles, y = acs, by = "GEOID")
# Joining the ACS data to into the quintiles data.

la_demographics %>% group_by(`PROP_NOSTAT_RES-2016`) %>% summarise(avg_count_hisp = mean(ACS16_5yr_B03002012), median_count_hisp = median(ACS16_5yr_B03002012))

la_demographics %>% group_by(`NOSTAT_RES-2016`) %>% summarise(avg_count_hisp = mean(ACS16_5yr_B03002012), median_count_hisp = median(ACS16_5yr_B03002012)) %>% write.csv("hispanic.csv")
# Descriptives on count Hispanic by nostat quintiles

la_demographics %>% group_by(`PROP_NOSTAT_RES-2016`) %>% summarise(avg_count_black = mean(ACS16_5yr_B03002004), median_count_black = median(ACS16_5yr_B03002004))

la_demographics %>% group_by(`NOSTAT_RES-2016`) %>% summarise(avg_count_black = mean(ACS16_5yr_B03002004), median_count_black = median(ACS16_5yr_B03002004)) %>% write.csv("black.csv")
# Descriptives on count black by nostat quintiles

la_demographics %>% group_by(`PROP_NOSTAT_RES-2016`) %>% summarise(avg_count_sfh = mean(ACS16_5yr_B25024002), median_count_sfh = median(ACS16_5yr_B25024002))

la_demographics %>% group_by(`NOSTAT_RES-2016`) %>% summarise(avg_count_sfh = mean(ACS16_5yr_B25024002), median_count_sfh = median(ACS16_5yr_B25024002)) %>% write.csv("sfh.csv")
# Descriptives on count single-family homes by nostat quintiles

la_demographics %>% group_by(`PROP_NOSTAT_RES-2016`) %>% summarise(avg_count_welfare = mean(ACS16_5yr_B19057002), median_count_welfare = median(ACS16_5yr_B19057002))

la_demographics %>% group_by(`NOSTAT_RES-2016`) %>% summarise(avg_count_welfare = mean(ACS16_5yr_B19057002), median_count_welfare = median(ACS16_5yr_B19057002))
# Descriptives on count of households on public assistance.

la_demographics <- la_demographics %>% mutate(hs_or_less = (ACS16_5yr_B15003002 + ACS16_5yr_B15003003 + ACS16_5yr_B15003004 + ACS16_5yr_B15003005 + ACS16_5yr_B15003006 + ACS16_5yr_B15003007 + ACS16_5yr_B15003008 + ACS16_5yr_B15003009 + ACS16_5yr_B15003010 + ACS16_5yr_B15003011 + ACS16_5yr_B15003012 + ACS16_5yr_B15003013 + ACS16_5yr_B15003014 + ACS16_5yr_B15003015 + ACS16_5yr_B15003016 + ACS16_5yr_B15003017 + ACS16_5yr_B15003018), some_coll = (ACS16_5yr_B15003019 + ACS16_5yr_B15003020 + ACS16_5yr_B15003021), postbac = (ACS16_5yr_B15003023 + ACS16_5yr_B15003024 + ACS16_5yr_B15003025))
# Consolidated education attainment into hs_or_less, some_coll, college, and postbac

la_demographics %>% group_by(`PROP_NOSTAT_RES-2016`) %>% summarise(avg_count_hs_or_less = mean(hs_or_less), median_count_hs_or_less = median(hs_or_less))

la_demographics %>% group_by(`NOSTAT_RES-2016`) %>% summarise(avg_count_hs_or_less = mean(hs_or_less), median_count_hs_or_less = median(hs_or_less)) %>% write.csv("hs_or_less.csv")
# Descriptives on count of hs_or_less by nostat quintiles

la_demographics %>% group_by(`PROP_NOSTAT_RES-2016`) %>% summarise(avg_count_collgrad = mean(ACS16_5yr_B15003022), median_count_collgrad = median(ACS16_5yr_B15003022))

la_demographics %>% group_by(`NOSTAT_RES-2016`) %>% summarise(avg_count_collgrad = mean(ACS16_5yr_B15003022), median_count_collgrad = median(ACS16_5yr_B15003022)) %>% write.csv("coll_grads.csv")
# Descriptives on count of college grads by nostat quintiles

la_demographics %>% group_by(`PROP_NOSTAT_RES-2016`) %>% summarise(avg_count_postbac = mean(postbac), median_count_postbac = median(postbac))

la_demographics %>% group_by(`NOSTAT_RES-2016`) %>% summarise(avg_count_postbac = mean(postbac), median_count_postbac = median(postbac)) %>% write.csv("postbac.csv")
# Descriptives on count of advanced degree holders by nostat quintiles

la_demographics <- la_demographics %>% mutate("below_25k" = (ACS16_5yr_B19001002 + ACS16_5yr_B19001003 + ACS16_5yr_B19001004 + ACS16_5yr_B19001005), "25k_to_50k" = (ACS16_5yr_B19001006 + ACS16_5yr_B19001007 + ACS16_5yr_B19001008 + ACS16_5yr_B19001009 + ACS16_5yr_B19001010), "50k_to_100k" = (ACS16_5yr_B19001011 + ACS16_5yr_B19001012 + ACS16_5yr_B19001013), "over_100k" = (ACS16_5yr_B19001014 + ACS16_5yr_B19001015 + ACS16_5yr_B19001016 + ACS16_5yr_B19001017))
# Consolidated income into four groupings

la_demographics %>% group_by(`PROP_NOSTAT_RES-2016`) %>% summarise(avg_count_over_100k = mean(over_100k), median_count_over_100k = median(over_100k))

la_demographics %>% group_by(`NOSTAT_RES-2016`) %>% summarise(avg_count_over_100k = mean(over_100k), median_count_over_100k = median(over_100k)) %>% write.csv("over_100k.csv")
# Descriptives on count of households earning more than 100k by nostat quintiles

la_demographics %>% group_by(`PROP_NOSTAT_RES-2016`) %>% summarise(avg_count_below_25k = mean(below_25k), median_count_below_25k = median(below_25k))

la_demographics %>% group_by(`NOSTAT_RES-2016`) %>% summarise(avg_count_below_25k = mean(below_25k), median_count_below_25k = median(below_25k)) %>% write.csv("below_25k.csv")
# Descriptives on count of householders earning less than 25k by nostat quintiles
```

# Descriptives for Alameda 
```{r}
alameda_shp <- alameda_shp %>% st_set_geometry(NULL)

alameda_shp <- alameda_shp %>% select(-c(66:76))

alameda_quintiles <- gather(alameda_shp, "count_type", "counts", c(5:65))
alameda_quintiles <- alameda_quintiles %>% arrange(GEOID)

alameda_quintiles <- alameda_quintiles %>% select(GEOID, State, County, count_type, YEAR, counts) %>% unite(col = "key", c(count_type, YEAR), sep = "-")

alameda_quintiles <- alameda_quintiles %>% group_by(key) %>% mutate(quintile1 = quantile(counts, probs = 0.2, na.rm = TRUE), quintile2 = quantile(counts, probs = 0.4, na.rm = TRUE), quintile3 = quantile(counts, probs = 0.6, na.rm = TRUE), quintile4 = quantile(counts, probs = 0.8, na.rm = TRUE))

alameda_quintiles <- alameda_quintiles %>% mutate(quintile = case_when(counts <= quintile1 ~ 1,
                                                                   (counts > quintile1 & counts <= quintile2) ~ 2,
                                                                   (counts > quintile2 & counts <= quintile3) ~ 3,
                                                                   (counts > quintile3 & counts <= quintile4) ~ 4,
                                                                   counts > quintile4 ~ 5,
                                                                   TRUE ~ 0)
                                              )

alameda_quintiles <- alameda_quintiles %>% select(GEOID, key, quintile)

alameda_quintiles <- spread(alameda_quintiles, key = key, value = quintile)

alameda_demographics <- left_join(x = alameda_quintiles, y = acs, by = "GEOID")

alameda_demographics %>% group_by(`PROP_NOSTAT_RES-2016`) %>% summarise(avg_count_hisp = mean(ACS16_5yr_B03002012), median_count_hisp = median(ACS16_5yr_B03002012))

alameda_demographics %>% group_by(`NOSTAT_RES-2016`) %>% summarise(avg_count_hisp = mean(ACS16_5yr_B03002012), median_count_hisp = median(ACS16_5yr_B03002012)) %>% write.csv("hispanic.csv")
# Descriptives on count Hispanic by nostat quintiles

alameda_demographics %>% group_by(`PROP_NOSTAT_RES-2016`) %>% summarise(avg_count_black = mean(ACS16_5yr_B03002004), median_count_black = median(ACS16_5yr_B03002004))

alameda_demographics %>% group_by(`NOSTAT_RES-2016`) %>% summarise(avg_count_black = mean(ACS16_5yr_B03002004), median_count_black = median(ACS16_5yr_B03002004)) %>% write.csv("black.csv")
# Descriptives on count black by nostat quintiles

alameda_demographics %>% group_by(`PROP_NOSTAT_RES-2016`) %>% summarise(avg_count_sfh = mean(ACS16_5yr_B25024002), median_count_sfh = median(ACS16_5yr_B25024002))

alameda_demographics %>% group_by(`NOSTAT_RES-2016`) %>% summarise(avg_count_sfh = mean(ACS16_5yr_B25024002), median_count_sfh = median(ACS16_5yr_B25024002)) %>% write.csv("sfh.csv")
# Descriptives on count single-family homes by nostat quintiles

alameda_demographics %>% group_by(`PROP_NOSTAT_RES-2016`) %>% summarise(avg_count_welfare = mean(ACS16_5yr_B19057002), median_count_welfare = median(ACS16_5yr_B19057002))

alameda_demographics %>% group_by(`NOSTAT_RES-2016`) %>% summarise(avg_count_welfare = mean(ACS16_5yr_B19057002), median_count_welfare = median(ACS16_5yr_B19057002))
# Descriptives on count of households on public assistance.

alameda_demographics <- alameda_demographics %>% mutate(hs_or_less = (ACS16_5yr_B15003002 + ACS16_5yr_B15003003 + ACS16_5yr_B15003004 + ACS16_5yr_B15003005 + ACS16_5yr_B15003006 + ACS16_5yr_B15003007 + ACS16_5yr_B15003008 + ACS16_5yr_B15003009 + ACS16_5yr_B15003010 + ACS16_5yr_B15003011 + ACS16_5yr_B15003012 + ACS16_5yr_B15003013 + ACS16_5yr_B15003014 + ACS16_5yr_B15003015 + ACS16_5yr_B15003016 + ACS16_5yr_B15003017 + ACS16_5yr_B15003018), some_coll = (ACS16_5yr_B15003019 + ACS16_5yr_B15003020 + ACS16_5yr_B15003021), postbac = (ACS16_5yr_B15003023 + ACS16_5yr_B15003024 + ACS16_5yr_B15003025))
# Consolidated education attainment into hs_or_less, some_coll, college, and postbac

alameda_demographics %>% group_by(`PROP_NOSTAT_RES-2016`) %>% summarise(avg_count_hs_or_less = mean(hs_or_less), median_count_hs_or_less = median(hs_or_less))

alameda_demographics %>% group_by(`NOSTAT_RES-2016`) %>% summarise(avg_count_hs_or_less = mean(hs_or_less), median_count_hs_or_less = median(hs_or_less)) %>% write.csv("hs_or_less.csv")
# Descriptives on count of hs_or_less by nostat quintiles

alameda_demographics %>% group_by(`PROP_NOSTAT_RES-2016`) %>% summarise(avg_count_collgrad = mean(ACS16_5yr_B15003022), median_count_collgrad = median(ACS16_5yr_B15003022))

alameda_demographics %>% group_by(`NOSTAT_RES-2016`) %>% summarise(avg_count_collgrad = mean(ACS16_5yr_B15003022), median_count_collgrad = median(ACS16_5yr_B15003022)) %>% write.csv("coll_grads.csv")
# Descriptives on count of college grads by nostat quintiles

alameda_demographics %>% group_by(`PROP_NOSTAT_RES-2016`) %>% summarise(avg_count_postbac = mean(postbac), median_count_postbac = median(postbac))

alameda_demographics %>% group_by(`NOSTAT_RES-2016`) %>% summarise(avg_count_postbac = mean(postbac), median_count_postbac = median(postbac)) %>% write.csv("postbac.csv")
# Descriptives on count of advanced degree holders by nostat quintiles

alameda_demographics <- alameda_demographics %>% mutate("below_25k" = (ACS16_5yr_B19001002 + ACS16_5yr_B19001003 + ACS16_5yr_B19001004 + ACS16_5yr_B19001005), "25k_to_50k" = (ACS16_5yr_B19001006 + ACS16_5yr_B19001007 + ACS16_5yr_B19001008 + ACS16_5yr_B19001009 + ACS16_5yr_B19001010), "50k_to_100k" = (ACS16_5yr_B19001011 + ACS16_5yr_B19001012 + ACS16_5yr_B19001013), "over_100k" = (ACS16_5yr_B19001014 + ACS16_5yr_B19001015 + ACS16_5yr_B19001016 + ACS16_5yr_B19001017))
# Consolidated income into four groupings

alameda_demographics %>% group_by(`PROP_NOSTAT_RES-2016`) %>% summarise(avg_count_over_100k = mean(over_100k), median_count_over_100k = median(over_100k))

alameda_demographics %>% group_by(`NOSTAT_RES-2016`) %>% summarise(avg_count_over_100k = mean(over_100k), median_count_over_100k = median(over_100k)) %>% write.csv("over_100k.csv")
# Descriptives on count of households earning more than 100k by nostat quintiles

alameda_demographics %>% group_by(`PROP_NOSTAT_RES-2016`) %>% summarise(avg_count_below_25k = mean(below_25k), median_count_below_25k = median(below_25k))

alameda_demographics %>% group_by(`NOSTAT_RES-2016`) %>% summarise(avg_count_below_25k = mean(below_25k), median_count_below_25k = median(below_25k)) %>% write.csv("below_25k.csv")
# Descriptives on count of householders earning less than 25k by nostat quintiles
```

# Descriptives for SF
```{r}
sf_shp <- sf_shp %>% st_set_geometry(NULL)

sf_shp <- sf_shp %>% select(-c(66:76))

sf_quintiles <- gather(sf_shp, "count_type", "counts", c(5:65))
sf_quintiles <- sf_quintiles %>% arrange(GEOID)

sf_quintiles <- sf_quintiles %>% select(GEOID, State, County, count_type, YEAR, counts) %>% unite(col = "key", c(count_type, YEAR), sep = "-")

sf_quintiles <- sf_quintiles %>% group_by(key) %>% mutate(quintile1 = quantile(counts, probs = 0.2, na.rm = TRUE), quintile2 = quantile(counts, probs = 0.4, na.rm = TRUE), quintile3 = quantile(counts, probs = 0.6, na.rm = TRUE), quintile4 = quantile(counts, probs = 0.8, na.rm = TRUE))

sf_quintiles <- sf_quintiles %>% mutate(quintile = case_when(counts <= quintile1 ~ 1,
                                                                   (counts > quintile1 & counts <= quintile2) ~ 2,
                                                                   (counts > quintile2 & counts <= quintile3) ~ 3,
                                                                   (counts > quintile3 & counts <= quintile4) ~ 4,
                                                                   counts > quintile4 ~ 5,
                                                                   TRUE ~ 0)
                                              )

sf_quintiles <- sf_quintiles %>% select(GEOID, key, quintile)

sf_quintiles <- spread(sf_quintiles, key = key, value = quintile)

sf_demographics <- left_join(x = sf_quintiles, y = acs, by = "GEOID")

sf_demographics %>% group_by(`PROP_NOSTAT_RES-2016`) %>% summarise(avg_count_hisp = mean(ACS16_5yr_B03002012), median_count_hisp = median(ACS16_5yr_B03002012))

sf_demographics %>% group_by(`NOSTAT_RES-2016`) %>% summarise(avg_count_hisp = mean(ACS16_5yr_B03002012), median_count_hisp = median(ACS16_5yr_B03002012)) %>% write.csv("hispanic.csv")
# Descriptives on count Hispanic by nostat quintiles

sf_demographics %>% group_by(`PROP_NOSTAT_RES-2016`) %>% summarise(avg_count_black = mean(ACS16_5yr_B03002004), median_count_black = median(ACS16_5yr_B03002004))

sf_demographics %>% group_by(`NOSTAT_RES-2016`) %>% summarise(avg_count_black = mean(ACS16_5yr_B03002004), median_count_black = median(ACS16_5yr_B03002004)) %>% write.csv("black.csv")
# Descriptives on count black by nostat quintiles

sf_demographics %>% group_by(`PROP_NOSTAT_RES-2016`) %>% summarise(avg_count_sfh = mean(ACS16_5yr_B25024002), median_count_sfh = median(ACS16_5yr_B25024002))

sf_demographics %>% group_by(`NOSTAT_RES-2016`) %>% summarise(avg_count_sfh = mean(ACS16_5yr_B25024002), median_count_sfh = median(ACS16_5yr_B25024002)) %>% write.csv("sfh.csv")
# Descriptives on count single-family homes by nostat quintiles

sf_demographics %>% group_by(`PROP_NOSTAT_RES-2016`) %>% summarise(avg_count_welfare = mean(ACS16_5yr_B19057002), median_count_welfare = median(ACS16_5yr_B19057002))

sf_demographics %>% group_by(`NOSTAT_RES-2016`) %>% summarise(avg_count_welfare = mean(ACS16_5yr_B19057002), median_count_welfare = median(ACS16_5yr_B19057002))
# Descriptives on count of households on public assistance.

sf_demographics <- sf_demographics %>% mutate(hs_or_less = (ACS16_5yr_B15003002 + ACS16_5yr_B15003003 + ACS16_5yr_B15003004 + ACS16_5yr_B15003005 + ACS16_5yr_B15003006 + ACS16_5yr_B15003007 + ACS16_5yr_B15003008 + ACS16_5yr_B15003009 + ACS16_5yr_B15003010 + ACS16_5yr_B15003011 + ACS16_5yr_B15003012 + ACS16_5yr_B15003013 + ACS16_5yr_B15003014 + ACS16_5yr_B15003015 + ACS16_5yr_B15003016 + ACS16_5yr_B15003017 + ACS16_5yr_B15003018), some_coll = (ACS16_5yr_B15003019 + ACS16_5yr_B15003020 + ACS16_5yr_B15003021), postbac = (ACS16_5yr_B15003023 + ACS16_5yr_B15003024 + ACS16_5yr_B15003025))
# Consolidated education attainment into hs_or_less, some_coll, college, and postbac

sf_demographics %>% group_by(`PROP_NOSTAT_RES-2016`) %>% summarise(avg_count_hs_or_less = mean(hs_or_less), median_count_hs_or_less = median(hs_or_less))

sf_demographics %>% group_by(`NOSTAT_RES-2016`) %>% summarise(avg_count_hs_or_less = mean(hs_or_less), median_count_hs_or_less = median(hs_or_less)) %>% write.csv("hs_or_less.csv")
# Descriptives on count of hs_or_less by nostat quintiles

sf_demographics %>% group_by(`PROP_NOSTAT_RES-2016`) %>% summarise(avg_count_collgrad = mean(ACS16_5yr_B15003022), median_count_collgrad = median(ACS16_5yr_B15003022))

sf_demographics %>% group_by(`NOSTAT_RES-2016`) %>% summarise(avg_count_collgrad = mean(ACS16_5yr_B15003022), median_count_collgrad = median(ACS16_5yr_B15003022)) %>% write.csv("coll_grads.csv")
# Descriptives on count of college grads by nostat quintiles

sf_demographics %>% group_by(`PROP_NOSTAT_RES-2016`) %>% summarise(avg_count_postbac = mean(postbac), median_count_postbac = median(postbac))

sf_demographics %>% group_by(`NOSTAT_RES-2016`) %>% summarise(avg_count_postbac = mean(postbac), median_count_postbac = median(postbac)) %>% write.csv("postbac.csv")
# Descriptives on count of advanced degree holders by nostat quintiles

sf_demographics <- sf_demographics %>% mutate("below_25k" = (ACS16_5yr_B19001002 + ACS16_5yr_B19001003 + ACS16_5yr_B19001004 + ACS16_5yr_B19001005), "25k_to_50k" = (ACS16_5yr_B19001006 + ACS16_5yr_B19001007 + ACS16_5yr_B19001008 + ACS16_5yr_B19001009 + ACS16_5yr_B19001010), "50k_to_100k" = (ACS16_5yr_B19001011 + ACS16_5yr_B19001012 + ACS16_5yr_B19001013), "over_100k" = (ACS16_5yr_B19001014 + ACS16_5yr_B19001015 + ACS16_5yr_B19001016 + ACS16_5yr_B19001017))
# Consolidated income into four groupings

sf_demographics %>% group_by(`PROP_NOSTAT_RES-2016`) %>% summarise(avg_count_over_100k = mean(over_100k), median_count_over_100k = median(over_100k))

sf_demographics %>% group_by(`NOSTAT_RES-2016`) %>% summarise(avg_count_over_100k = mean(over_100k), median_count_over_100k = median(over_100k)) %>% write.csv("over_100k.csv")
# Descriptives on count of households earning more than 100k by nostat quintiles

sf_demographics %>% group_by(`PROP_NOSTAT_RES-2016`) %>% summarise(avg_count_below_25k = mean(below_25k), median_count_below_25k = median(below_25k))

sf_demographics %>% group_by(`NOSTAT_RES-2016`) %>% summarise(avg_count_below_25k = mean(below_25k), median_count_below_25k = median(below_25k)) %>% write.csv("below_25k.csv")
# Descriptives on count of householders earning less than 25k by nostat quintiles
```

